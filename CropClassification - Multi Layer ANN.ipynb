{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from string import punctuation\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(module='sklearn*', action='ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig  = pd.read_csv('Crop Classification 2.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop record frequency\n",
      "Wheat       0.313736\n",
      "Cumin       0.255218\n",
      "Jowar       0.129166\n",
      "Castor      0.085018\n",
      "Maize       0.082013\n",
      "Rapeseed    0.076822\n",
      "Gram        0.058026\n",
      "Name: Crop Name, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Remove Crop categories with less than 5 % frequency\n",
    "dataframe_5per = df_orig[df_orig['Crop Name'] != 'Potato']\n",
    "dataframe_5per = dataframe_5per[dataframe_5per['Crop Name'] != 'Tobacco']\n",
    "dataframe_5per = dataframe_5per[dataframe_5per['Crop Name'] != 'Sugarcane']\n",
    "dataframe_5per = dataframe_5per[dataframe_5per['Crop Name'] != 'Fennel']\n",
    "\n",
    "print('Crop record frequency')\n",
    "print(dataframe_5per['Crop Name'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop record frequency :\n",
      "Wheat        0.304874\n",
      "Cumin        0.248009\n",
      "Jowar        0.125518\n",
      "Castor       0.082617\n",
      "Maize        0.079696\n",
      "Rapeseed     0.074652\n",
      "Gram         0.056387\n",
      "Fennel       0.019911\n",
      "Sugarcane    0.005044\n",
      "Tobacco      0.002336\n",
      "Potato       0.000956\n",
      "Name: Crop Name, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Remove Crop categories with less than 7 % frequency\n",
    "\n",
    "print('Crop record frequency :')\n",
    "print(df_orig['Crop Name'].value_counts(normalize=True))\n",
    "\n",
    "dataframe_7per = dataframe_5per[dataframe_5per['Crop Name'] != 'Gram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17240, 33)\n",
      "(17240,)\n"
     ]
    }
   ],
   "source": [
    "X = dataframe_7per.iloc[:, 2:35].values\n",
    "y = dataframe_7per.iloc[:, 1].values\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21576, 33)\n",
      "(21576,)\n"
     ]
    }
   ],
   "source": [
    "#SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE('minority')\n",
    "X, y = smote.fit_sample(X, y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, stratify = y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = X_test.shape[1]\n",
    "\n",
    "def baseline_model():\n",
    "    # define network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_shape=(n_words,), activation='relu'))\n",
    "    model.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "    # compile network\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    estimator = KerasClassifier(build_fn = baseline_model, epochs=200, batch_size=10, verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn = baseline_model, epochs=200, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0727 16:43:11.188840 12424 deprecation_wrapper.py:119] From C:\\Users\\Kunjan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0727 16:43:11.254049 12424 deprecation_wrapper.py:119] From C:\\Users\\Kunjan\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0727 16:43:11.292826 12424 deprecation_wrapper.py:119] From C:\\Users\\Kunjan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0727 16:43:11.293865 12424 deprecation_wrapper.py:119] From C:\\Users\\Kunjan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0727 16:43:11.326463 12424 deprecation_wrapper.py:119] From C:\\Users\\Kunjan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0727 16:43:11.336934 12424 deprecation.py:323] From C:\\Users\\Kunjan\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0727 16:43:11.689345 12424 deprecation_wrapper.py:119] From C:\\Users\\Kunjan\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.42727123000624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_Y = encoder.transform(y_test)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "\n",
    "results = cross_val_score(estimator, X_test, dummy_y, cv = kfold)\n",
    "print(results.mean()*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Case 1 : 3 layer network\n",
    "#model.add(Dense(50, input_shape=(n_words,), activation='relu'))\n",
    "#model.add(Dense(50, input_shape=(n_words,), activation='relu'))\n",
    "#model.add(Dense(50, input_shape=(n_words,), activation='relu'))\n",
    "#model.add(Dense(6, activation='softmax'))\n",
    "#Accuracy : 67.93288777984263\n",
    "\n",
    "#Case 2 : 2 Layer network\n",
    "#model = Sequential()\n",
    "#model.add(Dense(50, input_shape=(n_words,), activation='relu'))\n",
    "#model.add(Dense(50, input_shape=(n_words,), activation='relu'))\n",
    "#model.add(Dense(6, activation='softmax'))\n",
    "#Accuracy : 68.9060230729627\n",
    "\n",
    "#Case 3 : Single Layer network with 50 Neurons\n",
    "#model.add(Dense(50, input_shape=(n_words,), activation='relu'))\n",
    "#Accuracy : 71.8494362682229\n",
    "\n",
    "#Case 4 : Single Layer network with 75 Neurons\n",
    "#model.add(Dense(75, input_shape=(n_words,), activation='relu'))\n",
    "#Accuracy : 70.68928975592958"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
